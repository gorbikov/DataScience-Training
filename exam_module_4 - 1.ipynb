{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем импорты.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Включаем интерактивный режим (для отображения графиков.\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Вводные.\n",
    "trainPath = 'data/exam_module_4/1_variant_dna_sequence_mutation_prediction/input/train.csv'\n",
    "testPath = 'data/exam_module_4/1_variant_dna_sequence_mutation_prediction/input/test.csv'\n",
    "cvFraction = 0.15\n",
    "randomCeed = 777"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Определяем тип задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Task type: logistic regression or SVM')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Создаём фреймы и выделяем часть датасета на CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Смотрим огригинальные тренировочные данные.\n",
    "originalTrainDf = pd.read_csv(trainPath)\n",
    "originalTrainDf.info()\n",
    "originalTrainDf.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Смотрим огригинальные тренировочные данные.\n",
    "originalTestDf = pd.read_csv(testPath)\n",
    "originalTestDf.info()\n",
    "originalTestDf.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Формируем датафреймы из псевдорандомных выборок.\n",
    "trainDf = originalTrainDf.sample(frac=(1 - cvFraction), random_state=randomCeed).drop('mutation', axis=1)\n",
    "trainDfTarget = originalTrainDf.sample(frac=(1 - cvFraction), random_state=randomCeed)[['ID', 'mutation']]\n",
    "cvDf = originalTrainDf.drop(trainDf.index).drop('mutation', axis=1)\n",
    "cvDfTarget = originalTrainDf.drop(trainDfTarget.index)[['ID', 'mutation']]\n",
    "testDf = originalTestDf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Original train data:')\n",
    "pd.read_csv(trainPath).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Original test data:')\n",
    "pd.read_csv(testPath).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Train data:')\n",
    "trainDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Train target data:')\n",
    "trainDfTarget.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('CV data:')\n",
    "cvDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('CV target data:')\n",
    "cvDfTarget.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Test data:')\n",
    "testDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Определяем тип переменных в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Train data types:')\n",
    "trainDf.info()\n",
    "print('Train target data types:')\n",
    "trainDfTarget.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Если это необходимо провести препроцессинг данных, нужно ли применять алгоритмы понижения размерности?\n",
    "# Нужно ли убирать аномалии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Переводим первые 9 столбцов в цифры (по методу one-hot, one-hot столбцы добавляются в конце датафрейма).\n",
    "dummieCounter = 0\n",
    "for col in trainDf.columns:\n",
    "    if trainDf[col].dtypes == object:\n",
    "        dummieCounter += len(trainDf[col].unique())\n",
    "        print('Unique in ' + str(col) + ': ' + str(len(trainDf[col].unique())))\n",
    "print('Dummie columns: ' + str(dummieCounter))\n",
    "\n",
    "trainDf = pd.get_dummies(trainDf)\n",
    "cvDf = pd.get_dummies(cvDf)\n",
    "testDf = pd.get_dummies(testDf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"TrainDF: \")\n",
    "trainDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('CvDF: ')\n",
    "cvDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"TestDF: \")\n",
    "testDf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def time_series_plot(df):\n",
    "    \"\"\"Given dataframe, generate times series plot of numeric data by daily, monthly and yearly frequency\"\"\"\n",
    "    print(\"\\nTo check time series of numeric data  by daily, monthly and yearly frequency\")\n",
    "    if len(df.select_dtypes(include='datetime64').columns) > 0:\n",
    "        for col in df.select_dtypes(include='datetime64').columns:\n",
    "            for p in ['D', 'M', 'Y']:\n",
    "                if p == 'D':\n",
    "                    print(\"Plotting daily data\")\n",
    "                elif p == 'M':\n",
    "                    print(\"Plotting monthly data\")\n",
    "                else:\n",
    "                    print(\"Plotting yearly data\")\n",
    "                for col_num in df.select_dtypes(include=np.number).columns:\n",
    "                    __ = df.copy()\n",
    "                    __ = __.set_index(col)\n",
    "                    __T = __.resample(p).sum()\n",
    "                    ax = __T[[col_num]].plot()\n",
    "                    ax.set_ylim(bottom=0)\n",
    "                    ax.get_yaxis().set_major_formatter(\n",
    "                        matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "def numeric_eda(df, hue=None):\n",
    "    \"\"\"Given dataframe, generate EDA of numeric data\"\"\"\n",
    "    print(\"\\nTo check: \\nDistribution of numeric data\")\n",
    "    display(df.describe().T)\n",
    "    columns = df.select_dtypes(include=np.number).columns\n",
    "    figure = plt.figure(figsize=(20, 10))\n",
    "    figure.add_subplot(1, len(columns), 1)\n",
    "    for index, col in enumerate(columns):\n",
    "        if index > 0:\n",
    "            figure.add_subplot(1, len(columns), index + 1)\n",
    "        sns.boxplot(y=col, data=df, boxprops={'facecolor': 'None'})\n",
    "    figure.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if len(df.select_dtypes(include='category').columns) > 0:\n",
    "        for col_num in df.select_dtypes(include=np.number).columns:\n",
    "            for col in df.select_dtypes(include='category').columns:\n",
    "                fig = sns.catplot(x=col, y=col_num, kind='violin', data=df, height=5, aspect=2)\n",
    "                fig.set_xticklabels(rotation=90)\n",
    "                plt.show()\n",
    "\n",
    "    # Plot the pairwise joint distributions\n",
    "    print(\"\\nTo check pairwise joint distribution of numeric data\")\n",
    "    if hue == None:\n",
    "        sns.pairplot(df.select_dtypes(include=np.number))\n",
    "    else:\n",
    "        sns.pairplot(df.select_dtypes(include=np.number).join(df[[hue]]), hue=hue)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def top5(df):\n",
    "    \"\"\"Given dataframe, generate top 5 unique values for non-numeric data\"\"\"\n",
    "    columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in columns:\n",
    "        print(\"Top 5 unique values of \" + col)\n",
    "        print(df[col].value_counts().reset_index().rename(columns={\"index\": col, col: \"Count\"})[\n",
    "              :min(5, len(df[col].value_counts()))])\n",
    "        print(\" \")\n",
    "\n",
    "\n",
    "def categorical_eda(df, hue=None):\n",
    "    \"\"\"Given dataframe, generate EDA of categorical data\"\"\"\n",
    "    print(\"\\nTo check: \\nUnique count of non-numeric data\\n\")\n",
    "    print(df.select_dtypes(include=['object', 'category']).nunique())\n",
    "    top5(df)\n",
    "    # Plot count distribution of categorical data\n",
    "    for col in df.select_dtypes(include='category').columns:\n",
    "        fig = sns.catplot(x=col, kind=\"count\", data=df, hue=hue)\n",
    "        fig.set_xticklabels(rotation=90)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def eda(df):\n",
    "    \"\"\"Given dataframe, generate exploratory data analysis\"\"\"\n",
    "    # check that input is pandas dataframe\n",
    "    if type(df) != pd.core.frame.DataFrame:\n",
    "        raise TypeError(\"Only pandas dataframe is allowed as input\")\n",
    "\n",
    "    # replace field that's entirely space (or empty) with NaN\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    print(\"Preview of data:\")\n",
    "    display(df.head(3))\n",
    "\n",
    "    print(\"\\nTo check: \\n (1) Total number of entries \\n (2) Column types \\n (3) Any null values\\n\")\n",
    "    print(df.info())\n",
    "\n",
    "    # generate preview of entries with null values\n",
    "    if df.isnull().any(axis=None):\n",
    "        print(\"\\nPreview of data with null values:\")\n",
    "        display(df[df.isnull().any(axis=1)].head(3))\n",
    "        missingno.matrix(df)\n",
    "        plt.show()\n",
    "\n",
    "    # generate count statistics of duplicate entries\n",
    "    if len(df[df.duplicated()]) > 0:\n",
    "        print(\"\\n***Number of duplicated entries: \", len(df[df.duplicated()]))\n",
    "        display(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)).head())\n",
    "    else:\n",
    "        print(\"\\nNo duplicated entries found\")\n",
    "\n",
    "    print('cat')\n",
    "    # EDA of categorical data\n",
    "    categorical_eda(df)\n",
    "\n",
    "    print('num')\n",
    "    # EDA of numeric data\n",
    "    numeric_eda(df)\n",
    "    print('time')\n",
    "    # Plot time series plot of numeric data\n",
    "    time_series_plot(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eda(trainDf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 5. Провести EDA и вывести какие-то умозаключения и посмотреть на распределения признаков, на корреляции, на выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 6. Подумать над вариантом модели, для того чтобы решить задачу (либо ансамблем моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Так как n << m, лучше использовать логистическую регрессию, либо SMV without kernel.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 7. Подумать нужно ли применять Unsupervised learning подход для решения задачи?\n",
    "# Неоходима ли дополнительная информация?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 8. Обучить модель и вывести валидационный скор по метрике качества."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
